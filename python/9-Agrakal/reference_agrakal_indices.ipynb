{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor agrakal daily data (INDICES) - Python\n",
    "\n",
    "### Overview\n",
    "\n",
    "This sample makes the inventory of the reference indices for agrakal\n",
    "\n",
    "### Services used\n",
    "This sample uses *gRPC requests* in order to retrieve daily data from the dedicated hosted service. The queried endpoint in this script are:\n",
    "* *DailyPricesService*: to directly retrieve daily price objects from the server\n",
    "* *DailyBarsService*: to directly retrieve daily bars objects from the server\n",
    "\n",
    "### Modules required\n",
    "1. Systemathics packages:\n",
    "    * *systemathics.apis.services.topology.v1*\n",
    "    * *systemathics.apis.type.shared.v1*\n",
    "    * *google.type*\n",
    "2. Open source packages\n",
    "    * *googleapis-common-protos*\n",
    "    * *protobuf*\n",
    "    * *grpcio*\n",
    "    * *pandas*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run index agrakal daily reference data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.9/site-packages (1.53.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (3.17.3)\n",
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.9/site-packages (1.38.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: systemathics.apis in /opt/conda/lib/python3.9/site-packages (0.9.42)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.9/site-packages (from protobuf) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googleapis-common-protos protobuf grpcio pandas matplotlib systemathics.apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import google.type.date_pb2 as date\n",
    "import systemathics.apis.type.shared.v1.level_pb2 as level\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2 as daily_bars\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2_grpc as daily_bars_service\n",
    "import systemathics.apis.services.daily.v1.daily_prices_pb2 as daily_prices\n",
    "import systemathics.apis.services.daily.v1.daily_prices_pb2_grpc as daily_prices_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve authentication token\n",
    "The following code snippet sends authentication request and print token to console output in order to process the upcomming *gRPC queries*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImpwZDhjS2Z5Zi13QXkzOURpNENqWSJ9.eyJpc3MiOiJodHRwczovL2dhbnltZWRlLXByb2QuZXUuYXV0aDAuY29tLyIsInN1YiI6ImF1dGgwfDYwZGM5Mzk2YTZlOWRjMDA2Yjk2NmJkZiIsImF1ZCI6WyJodHRwczovL3Byb2QuZ2FueW1lZGUtcHJvZCIsImh0dHBzOi8vZ2FueW1lZGUtcHJvZC5ldS5hdXRoMC5jb20vdXNlcmluZm8iXSwiaWF0IjoxNjMxMTA5MTgwLCJleHAiOjE2MzExOTU1ODAsImF6cCI6Ijl5R0tzbGtFczFWNm9xRk9aa0h0a1V0NWkyNTVackpJIiwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCBzZXJ2aWNlczpiYXNpYyBzZXJ2aWNlczplbGV2YXRlZCIsInBlcm1pc3Npb25zIjpbInNlcnZpY2VzOmJhc2ljIiwic2VydmljZXM6ZWxldmF0ZWQiXX0.mFK-Q-0zfEGb3Qr0KDquXLJAxZdvgWKV3d1cIA_SoAtHbz2GJW6Oo-TSNiQk__3pPLPOwz-pZr8D5MoIDRNrwgn_tkVtMDoOw6E0T4RvmLBlEs5CQsd9-1SqgTHBgeGCEZqyqlUXl6rsZeQgw_W7TpsD6pC_PKPDC-M0NsjbD4KP8ghZyeAiXm0b3myoR9tvALnuGFkb-8aiIk6wUGr9ILA-69KfQIgw6VIvHeY0eD8fpBrFPCJr39Mpg3VGmmnYeR9QKj38m8G3bd8zNrEcDuaHhY6APjwA1rtI5yeCjwTAjC2N-k2XB7vhizATWIG9EbZ9CdFIVvevqGGgo7U94g'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token = f\"Bearer {os.environ['AUTH0_TOKEN']}\"\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and process request\n",
    "To request *DailyBarsService* and *DailyPricesService*, we need to specify:\n",
    "* Instrument identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Instrument selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set instrument identifier: exchange + ticker\n",
    "tickerexchange_array = [['SPX', 'XXXX'],\n",
    "                        ['NDX', 'XXXX'],\n",
    "                        ['VIX', 'XXXX'],\n",
    "                        ['V1X', 'XXXX'],\n",
    "                        ['V2TX', 'XXXX'],\n",
    "                       ]\n",
    "length = len(tickerexchange_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Request creation\n",
    "The following code snippet creates *gRPC client*, process request and ensure that the reply is not empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle dailyprices request creation for each instrument\n",
    "def get_dailyprices_request(ticker, exchange):\n",
    "    request = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker))\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle dailyprices request creation for each instrument\n",
    "def get_dailybars_request(ticker, exchange):\n",
    "    request = daily_prices.DailyPricesRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker))\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total asset requests:  6\n"
     ]
    }
   ],
   "source": [
    "# process all topologies requests\n",
    "credentials = grpc.ssl_channel_credentials()\n",
    "prices, bars =[],[] # prepare storage for responses\n",
    "today = datetime.today()\n",
    "      \n",
    "# iterate all instrument identifiers: exhange/ticker pairs\n",
    "for i in range(length):\n",
    "    with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "        credentials = grpc.ssl_channel_credentials(f.read())\n",
    "    with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "\n",
    "        ticker = tickerexchange_array[i][0]\n",
    "        exchange = tickerexchange_array[i][1]\n",
    "        \n",
    "        # --> prices\n",
    "        prices_request = get_dailyprices_request(ticker, exchange)\n",
    "        prices_service = daily_prices_service.DailyPricesServiceStub(channel)\n",
    "\n",
    "        # process the topologies request\n",
    "        prices_response = prices_service.DailyPrices(request=prices_request, metadata = [('authorization', token)])\n",
    "        prices.append(prices_response)\n",
    "        \n",
    "        # --> bars\n",
    "        bars_request = get_dailybars_request(ticker, exchange)\n",
    "        bars_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "\n",
    "        # process the topologies request\n",
    "        bars_response = bars_service.DailyBars(request=bars_request, metadata = [('authorization', token)])\n",
    "        bars.append(bars_response)\n",
    "        \n",
    "        \n",
    "# get tick count data\n",
    "print(\"Total asset requests: \", length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we have as many responses for each data type than the number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total daily prices responses:  6\n",
      "Total daily bars responses:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Total daily prices responses: \", len(prices))\n",
    "print(\"Total daily bars responses: \", len(bars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Retreive data\n",
    "The first code snippet allows to get the expected number of entries (daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet enables to export some metrics to *csv file*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# process all topologies responses\n",
    "filename = 'reference_agrakal_indices_{0:%Y%m%d}.csv'.format(today)\n",
    "\n",
    "with open(filename, mode='w') as dashboard_indices_file:\n",
    "    dashboard_indices_writer = csv.writer(dashboard_indices_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    # write 1rst row\n",
    "    dashboard_indices_writer.writerow(['Ticker', 'Exchange','Type', 'First Date', 'Last Date'])\n",
    "    \n",
    "    # Prices\n",
    "    for i in range(length):\n",
    "        tpm_price = prices[i].data   \n",
    "        ticker = tickerexchange_array[i][0]\n",
    "        exchange = tickerexchange_array[i][1]\n",
    "        \n",
    "        first_price, last_price = tpm_price[0], tpm_price[-1]\n",
    "        first_date = datetime(first_price.date.year, first_price.date.month, first_price.date.day)\n",
    "        last_date = datetime(last_price.date.year, last_price.date.month, last_price.date.day)\n",
    "        dashboard_indices_writer.writerow([ticker,exchange, 'PRICE', '{0:%Y/%m/%d}'.format(first_date), '{0:%Y/%m/%d}'.format(last_date)])\n",
    "        \n",
    "    # Bars\n",
    "    for i in range(length):\n",
    "        tpm_bar = bars[i].data   \n",
    "        ticker = tickerexchange_array[i][0]\n",
    "        exchange = tickerexchange_array[i][1]\n",
    "        \n",
    "        first_bar, last_bar = tpm_bar[0], tpm_bar[-1]\n",
    "        first_date = datetime(first_bar.date.year, first_bar.date.month, first_bar.date.day)\n",
    "        last_date = datetime(last_bar.date.year, last_bar.date.month, last_bar.date.day)\n",
    "        dashboard_indices_writer.writerow([ticker,exchange, 'BAR', '{0:%Y/%m/%d}'.format(first_date), '{0:%Y/%m/%d}'.format(last_date)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export every prices in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting prices to HYG-XNYS-dailyprices.csv ...\n",
      "Exporting prices to XLF-XNYS-dailyprices.csv ...\n",
      "Exporting prices to XLU-XNYS-dailyprices.csv ...\n",
      "Exporting prices to XLE-XNYS-dailyprices.csv ...\n",
      "Exporting prices to IBB-XNMS-dailyprices.csv ...\n",
      "Exporting prices to XLV-XNYS-dailyprices.csv ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "    tpm_price = prices[i].data   \n",
    "    my_dates=[datetime(p.date.year, p.date.month, p.date.day) for p in tpm_price]\n",
    "    my_prices = [p.price for p in tpm_price]\n",
    "    my_volumes = [p.volume for p in tpm_price]\n",
    "    \n",
    "    \n",
    "    d = {'Date': my_dates, 'Price': my_prices, 'Volume': my_volumes } # create dictonary\n",
    "    df = pd.DataFrame(data=d) # visualize dataframe\n",
    "    \n",
    "    filename = '{0}-{1}-dailyprices.csv'.format(tickerexchange_array[i][0],tickerexchange_array[i][1])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(\"Exporting prices to {} ...\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export every bars in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting bars to HYG-XNYS-dailybars.csv ...\n",
      "Exporting bars to XLF-XNYS-dailybars.csv ...\n",
      "Exporting bars to XLU-XNYS-dailybars.csv ...\n",
      "Exporting bars to XLE-XNYS-dailybars.csv ...\n",
      "Exporting bars to IBB-XNMS-dailybars.csv ...\n",
      "Exporting bars to XLV-XNYS-dailybars.csv ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "    tpm_bar = bars[i].data   \n",
    "    my_dates=[datetime(p.date.year, p.date.month, p.date.day) for p in tpm_bar]\n",
    "    my_opens = [b.open for b in tpm_bar]\n",
    "    my_highs = [b.high for b in tpm_bar]\n",
    "    my_lows = [b.low for b in tpm_bar]\n",
    "    my_closes = [b.close for b in tpm_bar]\n",
    "    my_volumes = [b.volume for b in tpm_bar]\n",
    "    \n",
    "    \n",
    "    d = {'Date': my_dates, 'Open': my_opens, 'High': my_highs, 'Low' : my_lows,'Close': my_closes, 'Volume': my_volumes }\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    filename = '{0}-{1}-dailybars.csv'.format(tickerexchange_array[i][0],tickerexchange_array[i][1])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(\"Exporting bars to {} ...\".format(filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
